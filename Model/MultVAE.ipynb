{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to dataset\n",
    "- MovieLens20M: https://www.kaggle.com/ntnhan54/movielens20m\n",
    "- MillionSong: https://www.kaggle.com/danh99/millionsong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:25.480764Z",
     "iopub.status.busy": "2021-06-24T16:15:25.480365Z",
     "iopub.status.idle": "2021-06-24T16:15:27.696069Z",
     "shell.execute_reply": "2021-06-24T16:15:27.695252Z",
     "shell.execute_reply.started": "2021-06-24T16:15:25.480684Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import  pandas as pd\n",
    "import os\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings; \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:27.697915Z",
     "iopub.status.busy": "2021-06-24T16:15:27.697607Z",
     "iopub.status.idle": "2021-06-24T16:15:27.770011Z",
     "shell.execute_reply": "2021-06-24T16:15:27.769173Z",
     "shell.execute_reply.started": "2021-06-24T16:15:27.697882Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:27.772506Z",
     "iopub.status.busy": "2021-06-24T16:15:27.771966Z",
     "iopub.status.idle": "2021-06-24T16:15:27.779675Z",
     "shell.execute_reply": "2021-06-24T16:15:27.778729Z",
     "shell.execute_reply.started": "2021-06-24T16:15:27.772434Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../input/movielens20m'\n",
    "path = 'movielens-VAE.pt'\n",
    "train_path = 'movielens-VAE-training.pt'\n",
    "metrics_path = 'history_MovieLens_VAE.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:36.096161Z",
     "iopub.status.busy": "2021-06-24T16:15:36.095806Z",
     "iopub.status.idle": "2021-06-24T16:15:43.312751Z",
     "shell.execute_reply": "2021-06-24T16:15:43.311731Z",
     "shell.execute_reply.started": "2021-06-24T16:15:36.096119Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_DIR + '/train.csv')\n",
    "val_data = pd.read_csv(DATA_DIR + '/val.csv')\n",
    "test_data = pd.read_csv(DATA_DIR + '/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.314412Z",
     "iopub.status.busy": "2021-06-24T16:15:43.314081Z",
     "iopub.status.idle": "2021-06-24T16:15:43.381159Z",
     "shell.execute_reply": "2021-06-24T16:15:43.380429Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.314374Z"
    }
   },
   "outputs": [],
   "source": [
    "nItems = train_data.sid.nunique()\n",
    "nItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.382684Z",
     "iopub.status.busy": "2021-06-24T16:15:43.382372Z",
     "iopub.status.idle": "2021-06-24T16:15:43.940409Z",
     "shell.execute_reply": "2021-06-24T16:15:43.939577Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.382657Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = sparse.csr_matrix((np.ones_like(train_data.uid), (train_data.uid.values, train_data.sid.values)), \n",
    "                             dtype='float64',\n",
    "                             shape=(train_data.uid.nunique(),nItems))\n",
    "\n",
    "\n",
    "val_data = sparse.csr_matrix((np.ones_like(val_data.uid), (val_data.uid.values, val_data.sid.values)), \n",
    "                             dtype='float64',\n",
    "                             shape=(val_data.uid.nunique(), nItems))\n",
    "\n",
    "test_data = sparse.csr_matrix((np.ones_like(test_data.uid), (test_data.uid.values, test_data.sid.values)), \n",
    "                             dtype='float64',\n",
    "                             shape=(test_data.uid.nunique(), nItems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.943677Z",
     "iopub.status.busy": "2021-06-24T16:15:43.943278Z",
     "iopub.status.idle": "2021-06-24T16:15:43.95329Z",
     "shell.execute_reply": "2021-06-24T16:15:43.952441Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.943639Z"
    }
   },
   "outputs": [],
   "source": [
    "class netflixDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, scr_matrix, eval = False,prop=0.2):\n",
    "        self.scr_matrix = scr_matrix\n",
    "        self.eval = eval\n",
    "        self.prop = prop\n",
    "      \n",
    "          \n",
    "    def __getitem__(self, idx):\n",
    "      \n",
    "      item = {}\n",
    "        \n",
    "      \n",
    "\n",
    "      if self.eval:\n",
    "        u_items = self.scr_matrix[idx,:].toarray()[0]\n",
    "        \n",
    "        nu_items = u_items.sum()       \n",
    "        val_size = int(nu_items*self.prop)\n",
    "        idx_labels = np.where(u_items == 1)[0]\n",
    "        data = np.ones_like(u_items)\n",
    "        \n",
    "        \n",
    "                \n",
    "        val_idx = np.random.choice(idx_labels, size=val_size, replace=False)                   \n",
    "        data[val_idx] = 0\n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "        item['data'] = torch.tensor(u_items*data,dtype=torch.float64)     \n",
    "        \n",
    "        item['ground_truth'] = torch.tensor(np.logical_not(data),dtype=torch.float64)             \n",
    "        \n",
    "        \n",
    "       \n",
    "      else:\n",
    "        item['data'] = torch.tensor(self.scr_matrix[idx,:].toarray(),dtype=torch.float64)\n",
    "      return item\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.scr_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.955775Z",
     "iopub.status.busy": "2021-06-24T16:15:43.955216Z",
     "iopub.status.idle": "2021-06-24T16:15:43.966325Z",
     "shell.execute_reply": "2021-06-24T16:15:43.965377Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.955736Z"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,n_Items, hidden=600, dimz= 200, p=0.5):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.n_Items = n_Items\n",
    "        self.dimz = dimz\n",
    "        self.hidden = hidden\n",
    "        self.p = p\n",
    "\n",
    "        self.inference = nn.Sequential(\n",
    "           \n",
    "#             nn.Dropout(self.p),\n",
    "            nn.Linear(self.n_Items,self.hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden,2*self.dimz)          \n",
    "        )\n",
    "        self.generative = nn.Sequential(\n",
    "            nn.Linear(self.dimz,self.hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.hidden,self.n_Items),\n",
    "            \n",
    "        )\n",
    "  \n",
    "        \n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return mu + std*eps* ( 1 if self.Mode =='train' else 0)\n",
    "\n",
    "\n",
    "    def forward(self, x,Mode='train'):       \n",
    "        self.Mode = Mode\n",
    "        x = F.normalize(x, p=2, dim=1)  \n",
    "        distribution = self.inference(x)\n",
    "\n",
    "\n",
    "\n",
    "        mu, logvar = distribution[:, :self.dimz], distribution[:, self.dimz:]\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        logit = self.generative(z)\n",
    "\n",
    "        \n",
    "        return logit, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.968303Z",
     "iopub.status.busy": "2021-06-24T16:15:43.967245Z",
     "iopub.status.idle": "2021-06-24T16:15:43.978335Z",
     "shell.execute_reply": "2021-06-24T16:15:43.97762Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.968274Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar,beta):\n",
    "    \n",
    "    CE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "   \n",
    "    return LL + beta*KLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.981762Z",
     "iopub.status.busy": "2021-06-24T16:15:43.981432Z",
     "iopub.status.idle": "2021-06-24T16:15:43.990282Z",
     "shell.execute_reply": "2021-06-24T16:15:43.989504Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.981737Z"
    }
   },
   "outputs": [],
   "source": [
    "def NDCG_at_k(labels, scores, k = 100):\n",
    "    device = scores.device\n",
    "    arg_sort_scores = torch.argsort(scores,1,descending=True)\n",
    "    arg_sort_labels = torch.argsort(labels,1,descending=True)\n",
    "\n",
    "\n",
    "    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n",
    "\n",
    "\n",
    "    tp = (1. /torch.log(torch.arange(2,2+k).float())).to(device)\n",
    "\n",
    "\n",
    "    dcg = (tp * pred_labels).sum(axis = 1)\n",
    "\n",
    "    idcg = torch.Tensor([tp[:min(int(n),k)].sum() for n in labels.sum(1)]).to(device)\n",
    "\n",
    "    ndcg = (dcg/idcg).mean()\n",
    "\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:43.993588Z",
     "iopub.status.busy": "2021-06-24T16:15:43.993315Z",
     "iopub.status.idle": "2021-06-24T16:15:44.000175Z",
     "shell.execute_reply": "2021-06-24T16:15:43.999403Z",
     "shell.execute_reply.started": "2021-06-24T16:15:43.993565Z"
    }
   },
   "outputs": [],
   "source": [
    "def Recall_at_k(labels, scores, k = 20):\n",
    "    device = scores.device\n",
    "    arg_sort_scores = torch.argsort(scores,1,descending=True)\n",
    "    arg_sort_labels = torch.argsort(labels,1,descending=True)\n",
    "\n",
    "    pred_labels = torch.gather(labels,1,arg_sort_scores[:,:k]).to(device)\n",
    "\n",
    "    denominator = labels.sum(1)\n",
    "    denominator[denominator > k] = k\n",
    "\n",
    "    return (pred_labels.sum(1) / denominator).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:44.001836Z",
     "iopub.status.busy": "2021-06-24T16:15:44.001375Z",
     "iopub.status.idle": "2021-06-24T16:15:44.016301Z",
     "shell.execute_reply": "2021-06-24T16:15:44.015485Z",
     "shell.execute_reply.started": "2021-06-24T16:15:44.0018Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, ndcg_k = [100], recall_k = [20,50]):\n",
    "    '''Evaluate model at Recall and NDCG metrics'''\n",
    "    metrics = {}\n",
    "    for k in ndcg_k:\n",
    "        metrics[f'ndcg@{k}'] = []\n",
    "    for k in recall_k:\n",
    "        metrics[f'recall@{k}'] = []\n",
    "    for data in val_loader:\n",
    "        X = data['data'].float().to(device)  \n",
    "        X = X.squeeze(1)\n",
    "\n",
    "\n",
    "        ground_truth = torch.stack([data['ground_truth'][i,:] for i in range(X.shape[0])])\\\n",
    "                      .squeeze(1).to(device)\n",
    "\n",
    "        pred ,_,_= model(X,Mode ='eval')\n",
    "\n",
    "        pred = pred.detach()\n",
    "\n",
    "\n",
    "        pred[X!=0] = -np.inf\n",
    "        for k in ndcg_k:\n",
    "            ndcg = NDCG_at_k(ground_truth,pred, k)\n",
    "            metrics[f'ndcg@{k}'] += [ndcg.item()]\n",
    "        for k in recall_k:\n",
    "            recall = Recall_at_k(ground_truth,pred, k)\n",
    "            metrics[f'recall@{k}'] += [recall.item()]\n",
    "    \n",
    "    for k in ndcg_k:\n",
    "        metrics[f'ndcg@{k}'] = np.mean(metrics[f'ndcg@{k}'])\n",
    "    for k in recall_k:\n",
    "        metrics[f'recall@{k}'] = np.mean(metrics[f'recall@{k}'])\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:15:44.017968Z",
     "iopub.status.busy": "2021-06-24T16:15:44.01772Z",
     "iopub.status.idle": "2021-06-24T16:15:44.025876Z",
     "shell.execute_reply": "2021-06-24T16:15:44.024872Z",
     "shell.execute_reply.started": "2021-06-24T16:15:44.017938Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare Model\n",
    "model = VAE(nItems).to(device)\n",
    "n_Epochs = 200\n",
    "\n",
    "# KL-Annealing for new training\n",
    "anneal = 0\n",
    "anneal_cap = 1\n",
    "anneal_steps = 1.0/200_000\n",
    "\n",
    "# prepare Data\n",
    "train_ds = netflixDataset(train_data)\n",
    "\n",
    "\n",
    "val_ds = netflixDataset(val_data,eval=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=500)\n",
    "\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3,weight_decay=0.01)\n",
    "cur_metric = -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T16:57:08.518358Z",
     "iopub.status.busy": "2021-06-24T16:57:08.518053Z",
     "iopub.status.idle": "2021-06-24T17:35:36.873379Z",
     "shell.execute_reply": "2021-06-24T17:35:36.872539Z",
     "shell.execute_reply.started": "2021-06-24T16:57:08.51833Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(metrics_path, 'a') as f:\n",
    "    \n",
    "    pbar = tqdm(range(n_Epochs),total = n_Epochs)\n",
    "    for epoch in pbar:\n",
    "        metrics = {}\n",
    "        train_loss =  []\n",
    "        # train phase\n",
    "        model.train()\n",
    "        train_phase = tqdm(train_dl,total = len(train_dl))\n",
    "        for data in train_phase:\n",
    "            x = data['data'].float().to(device)\n",
    "            x = x.squeeze(1)\n",
    "            optimizer.zero_grad()  \n",
    "\n",
    "\n",
    "            recon_x, mu, logvar = model(x)   \n",
    "\n",
    "\n",
    "            CE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "            KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "            loss =  CE + anneal * KLD            \n",
    "            anneal = min(anneal+anneal_steps,anneal_cap)   \n",
    "            loss.backward()      \n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            metrics['loss'] = train_loss[-1]\n",
    "            train_phase.set_postfix(metrics)\n",
    "\n",
    "        # Eval phases\n",
    "        model.eval()\n",
    "        metrics = evaluate(model, val_dl)\n",
    "        metrics['train_loss'] = np.mean(train_loss)\n",
    "\n",
    "        ndcg = list(metrics.values())[0]\n",
    "        if ndcg > cur_metric:\n",
    "            cur_metric = ndcg\n",
    "            torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': metrics['train_loss'],\n",
    "                    'evaluate': metrics,\n",
    "                    'beta': anneal\n",
    "                    }, path)\n",
    "        pbar.set_postfix(metrics)\n",
    "        # write metrics to file\n",
    "        s = ['{:.3f}'.format(v) for v in metrics.values()]\n",
    "        f.write(','.join(s) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:36.875458Z",
     "iopub.status.busy": "2021-06-24T17:35:36.874941Z",
     "iopub.status.idle": "2021-06-24T17:35:37.99008Z",
     "shell.execute_reply": "2021-06-24T17:35:37.988986Z",
     "shell.execute_reply.started": "2021-06-24T17:35:36.875417Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "                    'epoch': n_Epochs,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': metrics['train_loss'],\n",
    "                    'evaluate': metrics,\n",
    "                    'beta': anneal\n",
    "                    }, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:37.992867Z",
     "iopub.status.busy": "2021-06-24T17:35:37.992262Z",
     "iopub.status.idle": "2021-06-24T17:35:38.012676Z",
     "shell.execute_reply": "2021-06-24T17:35:38.011755Z",
     "shell.execute_reply.started": "2021-06-24T17:35:37.992822Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(metrics_path, header = None, names = metrics.keys(),index_col = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:38.030318Z",
     "iopub.status.busy": "2021-06-24T17:35:38.02977Z",
     "iopub.status.idle": "2021-06-24T17:35:38.201429Z",
     "shell.execute_reply": "2021-06-24T17:35:38.200476Z",
     "shell.execute_reply.started": "2021-06-24T17:35:38.03028Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(df['train_loss'], '-')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:38.203194Z",
     "iopub.status.busy": "2021-06-24T17:35:38.202848Z",
     "iopub.status.idle": "2021-06-24T17:35:38.374725Z",
     "shell.execute_reply": "2021-06-24T17:35:38.372629Z",
     "shell.execute_reply.started": "2021-06-24T17:35:38.203158Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(df['ndcg@100'],'-')\n",
    "plt.ylabel(\"ndcg@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:38.376472Z",
     "iopub.status.busy": "2021-06-24T17:35:38.376126Z",
     "iopub.status.idle": "2021-06-24T17:35:38.551165Z",
     "shell.execute_reply": "2021-06-24T17:35:38.550254Z",
     "shell.execute_reply.started": "2021-06-24T17:35:38.376437Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(df['recall@20'], 'x-')\n",
    "plt.ylabel(\"recall@20\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:38.554414Z",
     "iopub.status.busy": "2021-06-24T17:35:38.554051Z",
     "iopub.status.idle": "2021-06-24T17:35:38.735086Z",
     "shell.execute_reply": "2021-06-24T17:35:38.734251Z",
     "shell.execute_reply.started": "2021-06-24T17:35:38.554385Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(df['recall@50'], '-')\n",
    "plt.ylabel(\"recall@50\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:38.737276Z",
     "iopub.status.busy": "2021-06-24T17:35:38.736935Z",
     "iopub.status.idle": "2021-06-24T17:35:48.92889Z",
     "shell.execute_reply": "2021-06-24T17:35:48.927464Z",
     "shell.execute_reply.started": "2021-06-24T17:35:38.737239Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = netflixDataset(test_data,eval=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=512, shuffle = False, pin_memory = True)\n",
    "model.eval()\n",
    "evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:48.930599Z",
     "iopub.status.busy": "2021-06-24T17:35:48.930229Z",
     "iopub.status.idle": "2021-06-24T17:35:49.252356Z",
     "shell.execute_reply": "2021-06-24T17:35:49.251401Z",
     "shell.execute_reply.started": "2021-06-24T17:35:48.930562Z"
    }
   },
   "outputs": [],
   "source": [
    "# best model\n",
    "model1 = VAE(nItems).to(device)\n",
    "checkpoint = torch.load(path)\n",
    "\n",
    "model1.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-24T17:35:49.254085Z",
     "iopub.status.busy": "2021-06-24T17:35:49.253732Z",
     "iopub.status.idle": "2021-06-24T17:35:59.000143Z",
     "shell.execute_reply": "2021-06-24T17:35:58.999288Z",
     "shell.execute_reply.started": "2021-06-24T17:35:49.254047Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = netflixDataset(test_data,eval=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=500)\n",
    "model1.eval()\n",
    "evaluate(model1, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
