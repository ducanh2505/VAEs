\chapter{Kiến thức nền tảng}
\label{Chapter2}
\graphicspath{{Chapter2/Chapter2Figs}}

\textit{Tong chương này, đầu tiên chúng tôi sẽ trình bày về mô hình 
``Auto-Encoders'', một mạng nơ-ron được dùng để học đặc trưng ẩn dựa trên
phương pháp học không giám sát.
Sau đó, chúng tôi giới thiệu và trình bày về nền tảng xác suất 
của ``Variational Auto-encoders'' (VAEs) và lợi ích mang lại của 
mô hình này so với ``Auto-Encoder'' trong tác vụ học đặc trưng ẩn; 
Những điểm lợi này chính là lý do mà chúng tôi tập trung nghiên cứu VAEs. 
Bên cạnh đó, chúng tôi sẽ trình bày về ``Maximum Likelihood Estimation'', 
một phương pháp dùng để đánh giá các tham số của mô hình, đại diện cho các tham số 
của các phân phối xác suất dựa trên dữ liệu huấn luyện. 
Chương này đặc biệt là phần về ``Variational Auto-Encoders'' 
cung cấp những kiến thức nền tảng để có thể hiểu rõ về những đề xuất 
của chúng tôi ở chương kế tiếp.}


% \textit{Bên cạnh đó, chúng tôi sẽ trình bày về ``Log-likelihood fuctions'' - 
% là phép đo mức độ học của mô hình dựa trên các dữ liệu ta quan sát được 
% cũng như các lựa chọn Log-likelihood fucntion cho các bài toán học máy hiện nay.}
% 7->10; 15->20; 15->20; 10->15; 2 (~60)
\newpage

\section{Mô hình rút trích đặc trưng ``Auto-Encoder''}
\label{chap2/sec1}
Mô hình ``Auto-Encoder'' là một mạng nơ-ron truyền thẳng được huấn luyện
để cố gắng sao chép đầu vào của nó thành đầu ra. Bên trong ``Auto-Encoder''
có một lớp ẩn \textbf{\textit{h}} mô tả đặc trưng ẩn, gọi là véc-tơ biểu diễn ẩn đại diện cho đầu vào của nó.
 
Kiến trúc của một ``Auto-Encoder'' (được minh họa trong hình~\ref{fig_AE}) bao gồm hai phần:
\begin{itemize}
    \item Bộ mã hóa (encoder) ánh xạ véc-tơ đầu vào sang véc-tơ biểu diễn ẩn: 
    \begin{center}
        \begin{math}
            \centering
            \textbf{\textit{h}} = f(x)
        \end{math} 
            
    \end{center}
    \item Bộ giải mã (decoder) có nhiệm vụ cố gắng tái tạo lại véc-tơ đầu vào từ véc-tơ biểu diễn ẩn:
    \begin{center}
        \begin{math}
            \hat{x} = g(\textbf{\textit{h}}) = g(f(x))
        \end{math}
    \end{center}
\end{itemize}

\begin{figure}
    \centering
	\includegraphics[width=0.6\textwidth]{AE.jpg}
    \caption{Minh họa ``Auto-Encoder''}
    \label{fig_AE}
\end{figure}

``Auto-Encoder'' được huấn luyện bằng cách cực tiểu hóa hàm lỗi là độ sai lệch giữa dữ liệu được tái tạo
với dữ liệu đầu vào. 
\begin{equation}
\label{AE_loss}
    L(x, g(f(x)))
\end{equation}
Các hàm để tính độ lỗi thường được dùng là ``Mean-square error'' hoặc ``Binary cross-entropy''.
Tương tự như các mạng nơ-ron khác, ``Auto-Encoder'' có thể được huấn luyện bằng phương pháp ``Gradient-descent''
với thuật toán lan truyền ngược (``back-propagation'').



Khi thiết kế mô hình, kiến trúc của encoder, decoder
và kích thước của véc-tơ \textbf{\textit{h}} được xem như những siêu tham số của mô hình.
Bằng các cách thiết lập khác nhau, mô hình sẽ có những tính chất khác nhau. 
``Auto-Encoder'' với encoder và decoder là những hàm phi tuyến (cụ thể là mạng nơ-ron với hàm kích hoạt phi tuyến)
với khả năng tính toán quá mạnh hay trường hợp kích thước của véc-tơ \textbf{\textit{h}}
lớn hơn hoặc bằng so với véc-tơ đầu vào sẽ dẫn đến mô hình chỉ học cách sao chép thay vì trích xuất các đặc trưng ẩn từ dữ liệu. 

Thông thường, một ``Auto-Encoder'' sao chép một cách ``hoàn hảo'' đầu vào thành đầu ra
sẽ không có nhiều ý nghĩa. Thay vào đó, ``Auto-Encoder'' được thiết kế với các ràng buộc để không thể
học cách sao chép ``hoàn hảo'' mà chỉ có thể sao chép gần đúng, từ đó ta hy vọng quá trình 
huấn luyện ``Auto-Encoder'' sẽ thu được véc-tơ biểu diễn ẩn có những thông tin hữu ích.

Từ véc-tơ biểu diễn ẩn thu được trong quá trình huấn luyện ``Auto-Encoder'', ta có thể áp dụng mô hình này
như một mô hình trích xuất đặc trưng ẩn từ dữ liệu, làm đầu vào cho các tác vụ khác. 
Hoặc véc-tơ biểu diễn ẩn này có thể áp dụng được trong các tác vụ giảm chiều dữ liệu hỗ trợ cho các tác vụ
lưu trữ, truy vấn, tìm kiếm.

    \subsection{``Undercomplete Auto-Encoder''}
    \label{chap2/subsec11}
    Như đã trình bày trước đó, việc sao chép đầu vào thành đầu ra của ``Auto-Encoder'' không mang nhiều ý nghĩa.
    Ta cần các ràng buộc để có được \textbf{\textit{h}}
    nhận các thuộc tính hữu ích với các ràng buộc khi thiết kế mô hình.
    
    Một cách ràng buộc để mô hình có thể học được các đặc trưng ẩn từ dữ liệu
    là giới hạn véc-tơ đặc trưng ẩn \textbf{\textit{h}} có kích thước nhỏ hơn đáng kể so với véc-tơ đầu vào;
    tính chất này được gọi là ``under-complete''.
    
    Mô hình ``Auto-Encoder'' với kích thước \textbf{\textit{h}} nhỏ hơn đáng kể so với kích thước của véc-tơ đầu vào
    được gọi là ``Undercomplete Auto-Encoder''. Việc giới hạn này sẽ buộc mô hình phải nắm bắt các đặc trưng
    nổi bật nhất.

    Quá trình huấn luyện ``Undercomplete Auto-Encoder'' cũng giống với mô hình ``Auto-Encoder'',
    ta cần cực tiểu hóa hàm lỗi (công~thức~\ref{AE_loss}) là độ sai lệch giữa dữ liệu được tái tạo
    với dữ liệu đầu vào.

    ``Undercomplete Auto-Encoder'' là mô hình tốt để sử dụng cho các tác vụ tiêu biểu của ``Auto-Encoder'' truyền thống
    như trích xuất đặc trưng, giảm chiều dữ liệu 
    bởi vì tính chất ``under-complete'' của mô hình giúp dễ dàng thu được véc-tơ biểu diễn ẩn mang những thông tin hữu ích.


    \subsection{``Denoising Auto-Encoder''}
    \label{chap2/subsec12}
    
    Hàm lỗi của một ``Auto-Encoder'' thông thường sẽ ``phạt'' một mức nhất định với các mẫu dữ liệu được tái tạo lại
    khác với dữ liệu đầu vào. Điều này vô hình chung khuyến khích việc 
    \begin{math}
        f \circ g
    \end{math}
    là một hàm đồng nhất nếu khả năng tính toán của 
    \begin{math}
        f
    \end{math} 
    và
    \begin{math}
        g
    \end{math}
    cho phép. Nói đơn giản hơn, điều này là việc mô hình sao chép ``hoàn hảo'' đầu vào thành đầu ra của nó.
    Khi đó, véc-tơ biểu diễn ẩn sẽ không có các thông tin hữu ích. 

    Bằng cách thay đổi cách tính toán độ lỗi khi tái tạo lại, cụ thể là thêm nhiễu vào véc-tơ đầu vào, 
    sau đó tính toán độ lỗi là đầu ra được mô hình tái tạo lại so với đầu vào ban đầu như sau:
    \begin{equation}
        L(x, g(f(\tilde{x})))
    \end{equation}
    với 
    \begin{math} \tilde{x} \end{math}
    là véc-tơ đầu vào 
    \begin{math}
        x
    \end{math} 
    được thêm một độ nhiễu, ta có được mô hình ``Denoising Auto-Encoder'' (hình~\ref{fig_DAE}). 
    \begin{figure}
        \centering
        \includegraphics{DAE.pdf}
        \caption{Minh họa ``Denoising Auto-Encoder''}
        \label{fig_DAE}
    \end{figure}
    
    ``Denoising Auto-Encoder'' phải học cách khử độ nhiễu đã được thêm vào véc-tơ đầu vào,
    giảm khả năng sao chép của mô hình.






\section{``Variational Auto-Encoder''} \label{chap2/sec2}
        Variational Auto-encoders (VAEs) là một biến thể đặc biệt của Auto-encoder cơ bản. VAEs, ngoài là một mô hình rút trích đặc trưng ẩn dựa trên phương pháp học không giám sát, còn là một mô hình phát sinh dữ liệu hiệu quả. Khả năng phát sinh thêm dữ liệu là việc dựa trên những đặc trưng ẩn đã học được, VAEs dựa vào những đặc trưng này để thực hiện tác vụ phát sinh dữ liệu. Đây là một điểm khác biệt so với mô hình Auto-Encoder khi mà đặc trưng ẩn học từ Auto-encoder cơ bản không thể được sử dụng để phát sinh. Điều tạo nên sự khác biệt này là bởi đặc trưng ẩn có được từ VAEs là một phân phối xác suất. Auto-encoder hay kể cả denosing auto-encoder, việc nhận dữ liệu đầu vào, và trích xuất đặc trưng ẩn đều có thể được xem như là một phép chiếu dữ liệu ở chiều không gian cao lên một chiều không gian thấp hơn (thông thường thì số chiều của đặc trưng ẩn dược trích xuất sẽ nhỏ hơn so với dữ liệu đầu vào). Do đó, đặc trưng ẩn này, ta có thể xem như là một điểm dữ liệu mới thể hiện cho dữ liệu ban đầu ở một chiều không gian khác với số chiều thấp hơn. Còn VAEs, thì đặc trưng ẩn không còn là một điểm dữ liệu, thay vào đó sẽ là một ``phân phối xác suất''. Phân phối xác suất là quy luật cho ta biết với mỗi giá trị cụ thể của một đại lượng, một biến số nào đó, sẽ tương ứng với giá trị xác suất là bao nhiêu. 

        Tuy nhiên, để làm rõ được sự hiệu quả của variatioanl autoencoder trong việc phát sinh đặc trưng và phát sinh dữ liệu từ đặc trưng thì ta cần phải xét qua góc nhìn xác suất của mô hình này.
        Bản chất của một mô hình VAEs là một mô hình đồ thị (graphical models) - là một mô hình dùng để giải thích các mối quan hệ giữa các biến ngẫu nhiên trong xác suất thống kê. Và nền tảng của mô hình là Variation Inference - là một phương pháp cũng thuộc lĩnh vực xác suất thống kê với mục đích có thể ``giải thích'' được dữ liệu mà ta không quan sát được từ những dữ liệu mà ta đã có. Tận dụng sức mạnh của mạng nơ-ron trong lĩnh vực học máy, các hàm số xác suất được thay thành các mạng nơ-ron. Và thông qua việc huấn luyện mô hình để tìm ra bộ trọng số tốt nhất để giải quyết bài toán được giả định mà mô hình cần giải quyết. 

        Do sự liên hệ chặt chẽ với lĩnh vực xác suất, ở mục này, chúng tôi sẽ trình bày về nền tảng xác suất liên quan với mô hình Variational Auto-Encoder, bao gồm các khái niệm, định lý trong lĩnh vực xác suất thống kê để có thể dễ dàng trình bày nội dung của VAEs ở các mục tiếp theo, cũng như là cách huấn luyện cho mô hình VAEs. 
        

    \subsection{Nền tảng xác suất} \label{chap2/subsec21}
        
        Với sự tăng nhanh về số lượng dữ liệu có trên các nền tảng số thì nhu cầu cần một phương pháp có thể phân tích dữ liệu một cách tự động đang là một nhu cầu càng ngày càng tăng theo. Mục tiêu của học máy đó là phát triển các phương pháp mà có thể tự động phát hiện các mẫu ``patterm'' trong dữ liệu và sau đó sử dụng những ``patterm'' vừa khám phá được để có thể dự đoán dữ liệu trong tương lai hoặc để thực hiện các mục đích khác như thực hiện các quyết định/ dự đoán dựa trên ``những điều chưa chắc chắn''. Lý thuyết xác suất ``probability theory'' có thể được áp dụng cho bất kỳ vấn đề nào liên quan đến ``những điều chưa chắc chắn''. Trong máy học, ``những điều chưa chắc chắn'' đến từ nhiều dạng như: dự đoán/ quyết định nào là tốt nhất khi cho trước một vài điểm dữ liệu? Mô hình nào là tốt nhất khi cho trước các một vài điểm dữ liệu? \dots Do đó học máy có liên quan khá là gần gũi với lĩnh vực xác suất thống kê và khai thác dữ liệu, nhưng khác ở các trọng tâm và các thuật ngữ. 
        
        Trên lý thuyết thì có ít nhất hai cách diễn giải của xác suất:  ``diễn giải tần suất'' (frequentist interetation) và ``diễn giải bayesian''. Ở cách diễn giải thứ nhất thì xác suất được thể hiện thông qua việc thực hiện các thí nghiệm nhiều lần. Ví dụ như nếu ta thực hiện thí nghiệm tung đồng xu thì ta kì vọng rằng việc đồng xu xuất hiện mặt ngửa khoảng một nửa lần trong quá trình thực hiện. Còn ở cách diễn giải bayesian của xác suất thì thường được sử dụng để định lượng về ``những điều chưa chắc chắn''. Vậy nên ở góc nhìn này sẽ liên quan đến các thông tin hơn là việc lặp lại các thí nghiệm. Một trong những ưu điểm của cách diễn giải này đó là nó có thể được sử dụng để mô hình ``những điều chưa chắc chắn'' của sự việc/sự kiện mà ta đang quan tâm đến mà không có tần suất xuất dài hạn. Ví dụ liên hệ với các bài toán trong lĩnh vực học máy như chúng ta nhận một email và ta quan tâm đến việc tính phân phôi xác suất mà email vừa nhận là spam; hay trong bài toán chúng ta nhận thấy được một vật thể thông qua màn hình radar và ta muốn tính phân phối xác suất theo vật thể vừa được phát hiện chính xác là gì ? một con chim, hay máy bay? Trong những trường hợp trên thì ý tưởng việc lặp lại các thí nghiệm sẽ không giúp ích cho chúng ta trong việc giải quyết các vấn đề nhưng với Bayesian thì điều này khá là tự nhiên và có thể được áp dụng để giải quyết bất kỳ vấn đề nào liên quan tới những ``điều không chắc chắn''.
        
        \subsubsection{Định lý Bayes và ứng dụng trong lĩnh vực học máy}
        Trong lĩnh vực ``máy học'' và ``thống kê Bayesian'', chúng ta thường quan tâm đến việc thực hiện các phép suy diễn dữ liệu ẩn ta không quan sát được khi cho trước các dữ liệu ta quan đã quan sát được. Ví dụ như một mô hình phát hiện sản phẩm lỗi, thì ta sẽ quan tâm đến việc khi ta đã có các thông tin về sản phẩm, đây là dữ liệu ta đã quan sát được và từ đó ta suy diễn hay còn được gọi là dự đoán về tình trạng của sản phẩm mà tình trạng này chưa quan sát được. Giả sử rằng, ta có $x$ biến ngẫu nhiên thể hiện cho dữ liệu mà ta đã có, và $y$ là biến ngẫu nhiên của dữ liệu mà ta chưa quan sát được. Theo đó, ta sẽ quan tâm đến việc tìm ra được giá trị $y$ cụ thể khi cho trước giá trị $x$. Về xác suất, hay cụ thể ở đây, theo định lý Bayes, nếu ta có $p(x)$ là thông tin mà ta đã nắm được; và một vài mẫu dữ liệu $p(y|x)$ mà ta đã có trong việc thể hiện mối quan hệ giữa $y$ và $x$, cụ thể là giá trị của $y$ khi ta đã có $x$, thì theo công thức Bayes ta có: $$p(x|y) = \frac{p(y|x)p(x)}{p(y)}$$
        Trong đó, $p(x)$ được gọi là ``prior'', ``prior'' thể hiện ``kiến thức'' chủ quan ban đầu của chúng ta trước khi ta có bất kỳ về thông tin nào về liệu ẩn mà chưa quan sát được.
        Ta có thể chọn ``prior'' nào bất kỳ sao cho phù hợp với chúng ta, nhưng một điều chúng ta cần phải đảm bảo đó là ``prior'' phải là có giá trị khác không trên tất cả các giá trị có thể xuất hiện của $x$, kể cả khi giá trị đó rất hiếm khi xảy ra.
        $p(y|x)$ là ``likelihood'', mô tả mối quan hệ giữa $x$ và $y$ liên quan với nhau như thế nào, và trong trường hợp dữ liệu không liên tục (miền giá trị của $x$ và $y$ không phải là một miền giá trị liên tục), thì nó là xác suất của việc giá trị $y$ cụ thể khi ta đã biết về dữ liệu ẩn $x$. Chú ý rằng ``likelihood'' không phải là một phân phối xác suất của $x$, nó chỉ là phân phối cho $y$. Ta gọi $p(y|x)$ là ``likelihood của $x$ (khi cho trước $y$)'' hoặc là ``xác suất của $y$ khi cho trước $x$'' chứ không được gọi là ``likelihood của $y$''\cite{MacKay2003}.
        ``posterior'' $p(x|y)$ sẽ là giá trị mà ta quan tâm theo này quan điểm của Bayes. Nó thể hiện rằng chúng ta có được thông tin gì về $x$ khi ta có dữ liệu về $y$.
        Theo công thức trên, thì ta còn một giá trị nữa đó là $$p(y) = \int {p(y|x)p(x)\text{d}x = \mathrm{E}_X[p(y|x)]}$$ là ``marginal likelihood'' hay còn được gọi là ``evedience''. Trong công thức trên thì kí hiệu $\mathrm{E}$ thể hiện giá trị kỳ vọng của phân phối xác suất. Theo công thức của bayes thì, ``marginal likelihood'' độc lập với dữ liệu ẩn $x$, do đó ``marginal likelihood'' sẽ đóng vai trò đảm bảo giá trị của ``posterior'' sẽ được chuẩn hoá, có nghĩa là ``posterior'' sẽ có khoảng giá trị từ 0 đến 1. Ngoài tác dụng để chuẩn hoá ra thì ``marginal likelihood'' sẽ đóng vai trò trong việc lựa chọn mô hình ``model selection'' (là việc chọn ra mô hình tốt nhất, giữa các mô hình hoặc giữa các bộ siêu tham số). Tuy nhiên, với việc tính ``marginal likelihood'' là một giá trị tích phân, do đó thông thường việc tính toán giá trị chính xác cho ``marginal likelihood'' sẽ không dễ dàng. 


        \subsubsection{Computational diffficulties}
        Với góc nhìn này thì ``posterior'' sẽ là giá trị mà chúng ta quan tâm đến, nó thể hiện mối quan hệ giữa ``prior'' của chúng ta và dữ liệu. 
        Việc tính toán ``posterior'' sẽ giúp chúng ta giải quyết các vấn đề trong thực tế.
        Theo công thứ thì để tính toán ``posterior'' ta cần phải có: ``prior'', ``likelihood'' và ``evedience''. Hai giá trị ở trên tử số ta có thể dễ dàng xác định được trong hầu hết các trường hợp vì đó một phần là giả định của chúng ta về mô hình. Tuy nhiên, ở mẫu số ta cần tính:

        theo đó ta thấy được để tính được ``marginal likelihood'' thì ta cần tính biểu thức với dấu tích phân. Để tính giá trị này với dữ liệu ở chiều không gian thấp có thể không gặp nhiều khó khăn, nhưng khi tính toán ở những chiều không gian cao thì nó có thể trở thành một vấn đề nan giải. 
        Cụ thể ta thấy được rằng việc tính ``marginal likelihood'' sẽ thể hiện giá trị ``likelihood'' trung bình trên toàn bộ giá trị có thể xuất hiện của x, do đó x ở chiều không gian càng cao thì việc tính toán càng trở nên phức tạp hơn. 

        Chúng ta ca cần chú ý thêm một vài khó khăn khác có thể phải đối mặt khi tính toán ``posterior'' đó là việc lấy ``tổ hợp'' khi dữ liệu là rời rạc thay vì giá trị liên tục. 
        Ở miền không gian liên tục thì ta có thể áp dụng hàm số trong lĩnh vực giải tích để tính toán, tuy nhiên trong những trường hợp mà chiều không gian của dữ liệu không liên lục, dữ liệu rời rạc thì việc tính toán sẽ còn phải xét thêm việc lấy tổ hợp dữ liệu. 

        Khi dữ liệu có số chiều lớn thì việc tính chính xác giá trị ``posterior'' trong thực tiễn thường sẽ là một việc cực kỳ khó khăn và bất khả thi và ta cần một vài kĩ thuật xấp xỉ thường được dùng để giải quyết việc tính ``posterior''. 

        \subsubsection{Bài toán Inference}
        Inference là một lớp bài toán để giải quyết vấn đề tìm hiểu về nhưng thứ mà ta biết được dựa trên những thứ mà ta đã biết. Nói một cách khác thì bài toán này là tiến trình để có thể dưa ra kết luận cho một ước lượng, hay khoảng tin cậy hoặc xấp xỉ một phân phối về một ``biến ẩn'' (lateent variable) thường được gọi kết quả trong mẫu dữ liệu, dựa trên một vài các biến mà ta đã quan sát được thường được gọi là nguyên nhân trong mẫu dữ liệu. 

        Một cách cụ thể thì, ``Bayesian inferene'' là quá trình đưa ra các suy diễn thống kê dựa trên ``định lý Bayes''. Phương pháp Bayesian là một phương pháp trong lĩnh vực xác suất thống kê mà ở đó kiến thức biết được biết trước ``prior knowledge'' được mô hình hoá bởi một phân phối xác suất và được cập nhật mỗi khi có một quan sát mới và những thứ mà ta không chắc chắn hay không quan sát được sẽ được mô hình bởi một phân phôi xác suất khác. Một ví dụ kinh diển là về các tham số của bayesian inference, giả định rằng một mô hình mà dữ liệu x được phát sinh từ một phân phối xác suất mà phân phối xác suất này được xác định bỏi các tham số $\theta$, tuy nhiên giá trị của $\theta$ thì ta chưa biết. Bên cạnh đó, ta giả định rằng, ta có một vài kiến thức được biết từ $\theta$ được gọi là ``prior knowledge'', nó có thể là phân phối xác suất $p(\theta)$. Sau đó, mỗi khi ta có một quan sát x mới, ta có thể cập nhật lại ``prior knowledge'' về tham số $\theta$ thông qua định lý Bayes theo công thức :

        trong đó 

        
        Bayesian Inference là một vấn đề thường được phải giải quyết trong các bài toán trong lĩnh vực xác suất thống kê tuy nhiên trong lĩnh vực học máy, nhiều phương pháp được xây dựng dựa trên việc giải quyết vấn đề Bayesian Inference. Ví dụ: ``Gaussian mixture models'' được dùng để giải quyêt bài toán phân lớp, hay ``Latent Dirichlet Allocation'' để giải quyết bài toán phân loại chủ đề văn vản. Và cả hai mô hình kể trên đều được xây dựng dựa trên việc giải quyết bài toán Bayes Inference.  

        % \subsubsection{Computational diffficulties}
        % Theo công thứ thì để tính toán ``posterior'' ta cần phải có: ``prior'', ``likelihood'' và ``evedience''. Hai giá trị ở trên tử số ta có thể dễ dàng ác định được trong hầu hết các trường hợp vì đó một phần là giả định của chúng ta về mô hình. Tuy nhiên, ở mẫu số ta cần tính:

        % để tính giá trị này với dữ liệu ở chiều không gian thấp có thể không gặp nhiều khó khăn, nhưng khi tính toán ở những chiều không gian cao thì nó có thể trở thành một vấn đề nan giải. Khi dữ liệu có số chiều lớn thì việc tính chính xác giá trị ``posterior'' trong thực tiễn thường sẽ là một việc cực kỳ khó khăn và bất khả thi và ta cần một vài kĩ thuật xấp xỉ thường được dùng để giải quyết việc tính ``posterior''. 

        % Chúng ta ca cần chú ý thêm một vài khó khăn khác có thể phải đối mặt khi giải quyết bài toán bayesian inference  như là việc lấy ``tổ hợp'' khi dữ liệu là rời rạc thay vì giá trị liên tục. 

        % % Bài toán bayesian inference thông thường sẽ xuất hiện trong các phương pháp học máy mà giả định rằng có một Graphical model và khi mà cho trước một vài dữ liệu mà ta có thể quan sát được và mục đích của chúng ta là muốn tái tạo lại dữ liệu ẩn của mô hình. Xét ví dụ trong phương pháp Latent Dircichlet Allocation, một phương pháp để xác định chủ đề của một đoạn văn bản. Ta được cho trước một tập ``từ điển'' với kích thước V từ và có T chủ đề có thể có, mô hình này giải định rằng
        % % \begin{itemize}
        % %     \item Với mỗi chủ đề, tồn tại một phân phối xác suất ``topic-word''  trên toàn bộ tập từ điển (giả định về prior)
        % %     \item Với mỗi đoạn văn bản, có tồn tại một phân phối xác suất ``document-topic'' trên toàn bộ tập các chủ đề (một giả định prior khác)
        % %     \item Với mỗi từ trong trong văn bản được lấy mẫu từ các phân phối giải định ở trên, cụ thể là đầu tiên chúng ta sẽ lấy mẫu một chủ đè từ phân phối xác suất ``document-topic'' của đoạn văn bản, tiếp theo, từ phân phối xác suất ``topic-word'' ta lấy mẫu một từ từ phân phối xác suất đi kèm với chủ đề được lấy mẫu ở bước trước. 
        % % \end{itemize}
        % % Tên của phương pháp này là xuất phát từ giả định Dirichlet pior của mô hình. Mục tiêu của mô hình là có thể suy diễn ``latent topic'' từ từ điển ta quan sát được cũng như là có thể phân rã chủ đề của từng đoạn văn bản. Kể cả khi nếu chúng ta không đi sâu vào chi tiết của mô hình LDA, chúng ta có thể nói một cách đại khái rằng với w là một véc-tơ các từ có trong từ điển và z là véc-tơ liên hệ với những từ đó, chúng ta muốn suy diễn được z dựa trên các quan sát từ w theo công thức bayes đó là:

        % %         $\text{có một công thức ở đây}$
 
        
        \subsubsection{Variational inference}
        Variational inference(VI) là một phương pháp thường hay được sử dụng để giải quyết bài toán bayesian inference. 
        Phương pháp này sử dụng hướng tiếp cận là tìm ra xấp xỉ tốt nhất cho một phân phối xác suất bằng cách tìm ra bộ tham số tốt nhất định nghĩa cho phân phối khác, sao cho phân phối này sẽ ``gần'' với phân phối mà ta quan tâm. 
        
        Phương pháp VI, đầu tiên ta sẽ tìm một phân phối xác suất có cùng ``họ''(family) với phân phối xác suất mà ta quan tâm. Một họ phân phối xác suất là tập các phân phối xác suất được định nghĩa bởi bộ tham số có cùng định dạng. Ví như họ phân phối Gaussian sẽ được định nghĩa bởi $\mu$ là giá trị kỳ vọng (mean) và $\sigma$ là độ lệch chuẩn (standard devieation)
        Việc lựa chọn ``họ'' phân phối sẽ kiểm soát giữa độ phức tạp và độ chính xác của của phương pháp này. Nếu ta giả định rằng dữ liệu tuân theo một phân phối đơn giản thì kết quả suy diễn được sẽ không quá chính xác nhưng có thể dễ dàng tìm được nghiệm tối ưu. Ngược lại nếu ta lựa chọn ``họ'' phân phối phức tạp thì sẽ khó tìm đươc nghiệm tối ưu nhưng kết quả suy diễn sẽ có kết quả tốt hơn. 

        Sau khi xác định được ``họ'' phân phối xác suất dùng để xấp sỉ phân phối xác suất mà chúng ta quan tâm thì việc tiếp theo là làm sao để tìm ra được xấp xỉ tốt nhất. 
        Chúng ta xét độ lỗi E(q,p) giữa hai phân phối xác suất p và q, việc tìm ra bộ tham số tốt nhất được thể hiện bởi:
        $$\omega^* = \text{arg}_{\omega\in\Omega} \text{min}E(f_\omega,\pi) $$

        Do đó, sau khi xác định được một hàm lỗi để xấp xỉ phân phối xác suất mà chúng ta quan tâm.
        Việc tìm ra phân phối xác suất tốt nhất này trở thành một bài toán tìm nghiệm tối ưu nên phương pháp này có thể dễ dàng được áp dụng và mở rộng cho những trường hợp mà ta cần giải quyết một bài toán với quy mô dữ liệu lớn. 
        
        \subsubsection{Kullback-Leiber Devergence}
        Vậy trong bài toán variational inference thì làm sao để xác định hai phân phối xác suất có ``gần'' nhau hay không thì chúng ta sẽ dùng sự sai biệt Kullback-Leiber (KL).
        KL là môt
        Nếu p và q là hai phân phối xác suất, sự khai biệt Kullback-Leiber sẽ được định nghĩa như sau:
            

        \subsubsection{ ``Maximum Likelihood Estimation''}
        Trong lĩnh vực máy học, chúng ta sử dụng một mô hình để mô tả một tiến trình mà tổng hợp, phân tích tự động dữ liệu được thu thập để có thể giải quyết các vấn đề như tìm ra các đặc trưng, đưa ra các dự đoán dựa trên dữ liệu quan sát được. 
        Và để làm được mục đích trên thì mỗi mô hình sẽ được định nghĩa bởi một các tham số để thể hiện cho các phép tính toán của mô hình. 
        Ví dụ với mô hình hồi quy tuyến tính (linear regression),  giả sử rằng với dữ liệu x ta quan sát được và ta muốn dự đoán giá trị của y dựa trên x, theo mô hình này thì y sẽ được dự đoán như sau: 
        $$y = mx+c$$ 
        Trong đó m và c là các tham số của mô hình này. 
        Vậy nên với mỗi bộ tham số khác nhau thì dẫn đến kết quả trả về của mô hình là khác nhau.
        Việc huấn luyện một mô hình là việc tìm ra bộ tham số sao cho mô hình có thể đạt được kết quả tốt nhất trên các tập kiểm định. 
        Maximum likelihood Estimation(MLE) với ý tưởng là giả định các điểm dữ liệu mà ta quan sát được độc lập, và thể hiện một phân phối xác suất nào đó, và MLE sẽ xác định một hàm số với bộ tham số sao cho có thể tối đa được likelihood của mô hình.       
        MLE sẽ xác định xem với bộ tham số đó thì phân phối của kết quả trả về của mô hình có ``gần'' với phân phối của dữ liệu mà ta có.
        
        Nói một cách khác thì likelihood của mô hình với một bộ tham số cụ thể trên dữ liệu mà ta quan sát được sẽ thể hiện khả năng mà mà mô hình sẽ trả về là dữ liệu mà ta có.
        Thì việc cực đại likelihood là việc tối đa khả năng mà mô hình sẽ trả về kết quả chính là dữ liệu mà ta có.
        Cụ thể thì với một biến ngẫu nhiên x thể hiện cho dữ liệu và hàm mật độ  xác suất p(x|theta) cũng chính là likelihood của mô hình với theta là bộ tham số của mô hình thì Negative log-likelihood được thể hiện như sau 
        $$\mathcal{L}_x(\theta) = -\log p(x|\theta)$$
        Với dữ liệu x cố định và theta biên đổi, và hàm p(x|theta) thể hiện một mô hình với một bộ tham số cụ thể của theta. 
        Để cực đại likelihood của mô hình sẽ tương đương với việc tối  thiểu biểu thức trên. 
        Do đó, để tìm ra được bộ tham số cho mô hình học máy với MLE, thì ta sẽ tìm bộ tham số sao cho tối thiểu biểu thức trên.  
        
        
    


        \subsection{Variational Auto-encoder} 
        \subsubsection{Mô hình xác suất}
        \textbf{\textit{Mô hình xác suất}} là một mô hình được dùng để mô tả một phân 
        phối xác suất bằng cách sử dụng một đồ thị để mô tả các biến 
        ngẫu nhiên tương tác với nhau trong phân phối xác suất. Ở đây 
        chúng tôi sử dụng từ ``đồ thị'' là một định nghĩa về cấu trúc 
        dữ liệu được mô tả trong lĩnh vực lý thuyết đồ thị. Đồ thị 
        bao gồm các đỉnh được kết nối trực tiếp với nhau thông qua 
        các cạnh. Vì cấu trúc của mô hình đươc mô tả bằng đồ thị cho 
        nên những mô hình này còn được gọi với một tên gọi khác là 
        ``Graphical model''.
        Mô hình xác suất thể hiện những khía cạnh mà mang tính chất ``chưa chắc chắn'' (uncertain) của một ``thí nghiệm'' dưới dạng của một phân phối xác suất. Ở đây, xét trong quá trình giải quyết một vấn đề nào đó bất kỳ, một thí nghiệm được thực hiện để kiểm chứng lý thuyết, ... thì cụm từ ``chưa chắc chắn'' mang ý nghĩa là chỉ những điểm dữ liệu mà chúng ta chưa quan sát hay chưa thu thập được, do đó về giá trị cụ thể, khoảng dữ liệu và tính chất của những điểm dữ liệu này chúng ta chưa có thể kiểm chứng được. Mô hình xác suất mang lại cho chúng các công cụ để có thể xây dựng một mô hình học, thuật toán học, cách đưa ra dự đoán từ mô hình đã được huấn luyện và cả việc lựa chọn mô hình. Các công cụ này nhất quán và đồng nhất do nó dựa trên nền tảng 


        Mục tiêu của một mô hình học máy hay mô hình học sâu là có thể giải quyết được các vấn đề mà ta không có một cách trực tiếp để giải quyết, tuy nhiên bên cạnh đó lại có dữ liệu được thu thập về vấn đề đó. Điều đó có nghĩa là ta cần xây dựng các mô hình học có thể ``hiểu'' được hình ảnh, âm thanh tiếng nói hay một đoạn văn bản. Nhưng để xây dựng được các mô hình này ta sẽ phải đối mặt với nhiều khó khăn cần giải quyết. Một trong những khó khăn đó là việc dữ liệu ta thu thập được thường có các cấu trúc phức tạp và dữ liệu ở chiều không gian cao, để có thể xử lý được những dữ liệu như vậy là điều không dễ dàng. 

        Điểm mạnh của một mô hình xác suất đó là khả năng có thể giảm được chi phí cho việc thể hiện một mô hình xác suất và cũng như là chi phí cho việc huấn luyện cũng như suy diễn. Cơ chế hoạt động chính của mô hình xác suất cho phép tát cả các phép tính được thực hiện với thời gian thực thi và bộ nhớ hơn so với các mô hình mô hình hoá dữ liệu. Một lợi ích khác trong việc sử dụng mô hình xác suất khác đó là cho phép chúng ta tách biệt các thể hiện của ``kiến thức'' một cách chi tiết từ quá trình huấn luyện hay quá trình suy diễn. Điều này làm cho các mô hình dễ dàng để cài đặt và ``debug''. Chúng ta có thể thiết kế, phân tích và đánh quá thuật toán huấn luyện và thuật toán suy diễn mà có thể áp dụng rộng rãi ở tất cả các loại đồ thị. Một cách độc lập, chúng ta có thể thiết kế các mô hình mà có thể nắm bắt được mối quan hệ mà chúng ta tin rằng nó quan trọng trong dữ liệu mà chúng ta có. Sau đó chugn ta có thể kết hợp các thuật toán và các cấu trúc khác nhau và có các ``tích Đề-Các'' bất kỳ nào mà phù hợp có thể để áp dụng. Tuy nhiên nó sẽ khó hơn trong việc thiết kế một thuật toán ``end-to-end'' cho tất cả các trường hợp.
        \subsubsection{variational Auto-encoder}
        Với góc nhìn mạng nơ ron thông thường thì Variational autoencoder cũng chỉ là một mạng nơ ron đơn giản với cấu trúc hai phần như autoencoder cơ bản, gồm encoder và decoder. 
        Encoder được dùng để trích xuất đặc trưng ẩn từ dữ liệu, điểm khác biệt so với autoencoder cơ bản là encoder của VAEs sẽ là một phân phối xác suất.
        Và tương tự thì decoder sẽ là mạng nơ ron cố gắng để tái tạo lại dữ liệu ban đầu từ đặc trưng ẩn.
        Tuy nhiên để hiểu rõ hơn về nền tảng toán học cũng như xác suất trong mô hình chúng tôi sẽ trình bày mô hình VAEs dưới góc độ là một mô hình xác suất.
        Variational autoenncoder là một mô hình graphical có hướng mô tả mối quan hệ giữa dữ liệu quan sát được và đặc trưng ẩn.
        Xét graphical model thể hiện cho mô hình VAE như sau:

        theo đó thì variational autoencode bao gồm một biến x thể hiện cho dữ liệu, đây là biến dữ liệu quan sát được, và z là biến ẩn thể hiện cho đặc trưng ẩn của dữ liệu. 
        Quá trình phát sinh dữ liệu của VAE được thực hiện như sau: 
        
        Với mỗi điểm dữ liệu i thì: 
        \begin{itemize}
            \item Đặc trưng ẩn $z_i$ được lấy mẫu từ phân phối p(z)
            \item điểm dữ liệu $x|i$ được lấy mẫu từ phân phối p(x|z)
        \end{itemize}

        Cụ thể thì biến đặc trưng ẩn z được chọn ra từ một phân phố prior p(z). Điểm dữ liệu x có một phân phối liklihood p(x|z).
        Mô hình định nghĩa một phân phối hợp của dữ liệu và đặc trưng ẩn: p(x,z). 
        Chúng ta có thể phân tách phân phối hợp trên thành prior và likelihood như sau: p(x,z) = p(x|z)p(z). Đây chíh là mục tiêu chính khi ta xét variational auto-encoder dưới góc độ của xác suất.


        Mô hình này sử dụng phương pháp xấp sỉ variational inference để tìm ra đặc trưng ẩn,đây cũng là lý do dẫn đến cái tên variational autoencoder. và VAEs có thể được huấn luyện dựa trên các thuật toán dựa trên gradient truyền thống.
        
        
        Tiếp theo, ta xét đến việc suy diễn trong mô hình này. 
        Mục tiêu của việc suy diễn là tìm ra được một giá trị ``tốt'' thể hiện cho đặc trưng ẩn khi ta có các điểm dữ liệu, hay nói cách khác là ta tính posterior.
        Theo công thức bayes thì 
        $$p(z|x) = \frac{p(z|x)p(z)}{p(x)}$$
        theo như những gì đã trình bày ở những phần trên thì phần mẫu số được gọi là marginal likelihood. 
        Và marginal likelihood sẽ không dẽ dang tính toán được một cách chính xác khi đặc trưng ẩn ở không gian có số chiều cao. 

        Do đó, vairational inference được áp dụng để xấp xỉ phân phối posterior này.
        VI xấp xỉ posterior thông qua một lớp phân phối xác suất $q_\lambda(z|x)$.
        trong đó $\lambda$ thể hiện cho bộ tham số định nghĩa cho phân phối q, ví dụ nếu q là phân phối Gaussian thì $\lambda_{xi} = (\mu_{xi},\sigma^2_{x_i})$.
        
        Tiếp đến, Kullback Leiber Devergence được sử dụng để xấp xỉ posterior. 
        với $$KL(q_\lambda(z|x) || p (z|x)) = E_q[log q_\lambda(z|x)] - E_q[log p(x,z)] + \log p(x)$$
        Mục tiêu của chúng ta là tìm ra bộ tham số $\lambda$ sao cho tối thiểu được sự sai biệt trên. với $q^*$ là phân phối q lý tưởng để xấp sỉ posterior thì ta có
        $$q^*_\lambda(z|x) = \text{arg min}_\lambda KL(q_\lambda(z|x)|| p(x))$$
        Tuy nhiên ta vẫn chưa có thể tính được trực tiếp bởi trong công thức thì vân còn xuất hiện p(x), marginial likelihood không thể tính một cách trực tiếp. 
        Xét biến đổi sau:


        theo bất đẳng thức jensen thì Kullback-Leiber divergence luôn lớn hơn hoặc bằng không. 
        Điều này có nghĩa rằng thay vì tối thiểu hoá KL thì ta sẽ thực hiện cực đại hoá ELBO.
        
        Ở trên là lý thuyết nền tảng về xác suất của mô hình VAEs, tiếp theo ta sẽ liên hệ với mạng nơ ron để thể hiện cho mô hình.
        Mục tiêu cuối cùng của chúng ta là tìmm ra bộ tham số có thể xấp xỉ được posterior $q_theta(z|x,lamda) p(z|x,lamda)$ thông qua một mạng nơ ron thường được gọi là  ``inference network'' hay là encoder. Mạng này nhận đầu vào là dữ liệu x và trả về kết quả là bộ tham số lamda thể hiện phân phối xác suất của đặc trưng ẩn. 
        Bên cạnh đó, sẽ có một mạng nơ ron được gọi là ``genetive netowrk'' hay còn được biết đến là decoder thể hiện cho likelihood $p_phi(x|z)$ của mô hình. 
        Tiếp theo đặc trưng ẩn sẽ được lấy mẫu từ phân phối xác suất trả ra từ encoder, đây chính là bước đầu tiên trong mô hình xác suất nói trên.
        Dữ liệu đầu vào của decoder là đặc trưng ẩn được lấy mẫu dựa trên phân phối của đặc trưng ẩn, và decoder sẽ cố gắng tái tạo lại dữ liệu ban đầu từ đặc trưng ẩn z, đây chính là bước thứ hai trong mô hình xác suất.
        Inference network và generative network sẽ có bộ tham số tương ứng là theta và phi.
        Thông thường bộ tham số là các trọng số và bias trong một mạng nơ ron thông thường. 
        Để huấn luyện mô hình ta sẽ cực đại ELBO bằng các phương pháp tối ưu bộ tham số như trong các mạng nơ ron thông thường. 



  
        
        

       
    % \subsection{Độ sai biệt ``Kullback-Leiber Devergence'' giữa hai phân phối xác suất}  \label{chap2/subsec23}