\chapter{Thí nghiệm}
\label{Chapter4}

\textit{Trong chương này, chúng tôi trình bày các kết quả thí nghiệm nhằm đánh giá những nội dung trình bày ở chương \ref{Chapter3}. Bộ dữ liệu được dùng để tiến hành các thí nghiệm là bộ Movielens-20M \cite{Ml20M} và Million Song Dataset \cite{MSD}; bên cạnh đó, độ đo được sử dụng để đánh giá khả năng đưa ra gợi ý của mô hình là Normalized Discounted Cumulative Gain (NDCG) và  Recall. Kết quả thí nghiệm cho thấy mô hình do chúng tôi cài đặt đạt được kết quả xấp xỉ so với kết quả được công bố trong bài báo \cite{mvae}. Bên cạnh đó, các kết quả thí nghiệm cũng chứng tỏ mô hình đưa ra sản phẩm gợi ý sử dụng mô hình variational auto-encoder có khả đưa ra gợi ý phù hợp hơn so với auto-encoders cơ bản, đặc biệt là trong trường hợp dữ liệu tương tác của người dùng thưa. Ngoài ra, các kết quả thí nghiệm cũng cho thấy việc thay đổi hàm mục tiêu giúp mô hình đưa ra kết quả tốt hơn cho bài toán gợi ý sản phẩm so với các hàm mục tiêu thường được sử dụng khi huấn luyện variational auto-encoder}


\section{Tập dữ liệu sử dụng}
\label{chap4sec1}
Chúng tôi tiến hành thí nghiệm trên các tập dữ liệu vừa và lớn ở các lĩnh vực khác nhau là Movielens-20M \cite{Ml20M} 
và Million Song Dataset (MSD) \cite{MSD}; đây là các tập dữ liệu thường được dùng cho bài toán xây dựng hệ thống gợi ý
với hướng tiếp cận ``Collaborative Filtering''. 
\begin{itemize}
    \item Tập dữ liệu Movielens-20M bao gồm dữ liệu đánh giá của 138,000 người dùng với khoảng 27,000 bộ phim,
    với 20 triệu đánh giá.
    \item Tập dữ liệu Million Song Dataset bao gồm dữ liệu tương tác (số lượt nghe) của khoảng 1 triệu người dùng và hơn 300,000 bài hát, với hơn 48 triệu tương tác.
\end{itemize}

Để có thể đánh giá kết quả đạt được so với kết quả trong bài báo \cite{mvae} một cách tốt nhất,
chúng tôi thực hiện các bước tiền xử lí được các tác giả mô tả trong bài báo \cite{mvae}.
\begin{itemize}
    \item Tập dữ liệu Movielens-20M: chúng tôi giữ lại những người dùng đã đánh giá ít nhất 5 bộ phim trở lên. 
    \item Tập dữ liệu Million Song Dataset: chúng tôi chỉ giữ lại những bài hát được nghe bởi ít nhất 200 người dùng, và những người dùng nghe ít nhất 20 bài hát trong số còn lại.
\end{itemize}

Sau khi lọc dữ liệu theo điều kiện đã nói, số lượng người dùng, số lượng sản phẩm, số lượng tương tác, tỉ lệ tương tác giữa người dùng và sản phẩm được mô tả trong bảng~\ref{table_dataset}.
\begin{table}[]
\centering
    \begin{tabular}{|l|c|c|}
    \hline
                                                & \textbf{MovieLens} & \textbf{MSD}    \\ \hline
    \textbf{Số lượng người dùng}                  & 136,677            & 571,355         \\ \hline
    \textbf{Số lượng sản phẩm}                    & 20,108             & 41,140          \\ \hline
    \textbf{Số lượng tương tác}                   & 10.0M              & 33.6M           \\ \hline
    \textbf{\% tương tác}                         & 0.36               & 0.14            \\ \hline
    \textbf{Số người dùng trong tập ``held-out``} & \textbf{10,000}    & \textbf{50,000} \\ \hline
    \end{tabular}
    \label{table_dataset}
    \caption{Thống kê số lượng người dùng, số lượng sản phẩm, số lượng tương tác trong các tập dữ liệu}    
\end{table}


Chúng tôi tiến hành ``chuẩn hóa'' dữ liệu về dạng ``implicit feedback''. Đối với tập dữ liệu Movielens, chúng tôi 
chúng tôi chuyển dữ liệu thành dạng ma trận tương tác nhị phân, với các đánh giá của người dùng từ 4 trở lên (nghĩa là người dùng thích bộ phim đó) mang giá trị 1 trong ma trận nhị phân.
Với tập dữ liệu MSD, chúng tôi chỉ chuyển các giá trị số lượt nghe của người dùng thành giá trị nhị phân.

Với mỗi tập dữ liệu, chúng tôi lần lượt lấy ra một số lượng người dùng bằng nhau cho tập đánh giá (validation) và tập kiểm tra (testing), gọi chung đây là các tập ``held-out''. Phần còn lại sẽ là tập dữ liệu huấn luyện (training).


\section{Các thiết lập thí nghiệm}
\label{setup_experiment}

Để đánh giá khả năng tổng quát hóa của mô hình, chúng tôi chia dữ liệu thành 3 phần như đã trình bày trong phần~\ref{chap4sec1}, bao gồm các tập huấn luyện, đánh giá, kiểm tra. Với số người dùng của các tập ``held-out'' (tập dữ liệu đánh giá và kiểm tra) lần lượt là 10,000 và 50,000 cho hai bộ dữ liệu MovieLens và MSD.

Để huấn luyện mô hình, chúng tôi sử dụng toàn bộ dữ liệu tương tác của người dùng trong tập huấn luyện. Để đánh giá mô hình, chúng tôi chọn ngẫu nhiên 80\% tương tác của mỗi người dùng để làm đầu vào của mô hình. Sau đó đánh giá các sản phẩm được dự đoán bởi mô hình dựa trên 20\% tương tác còn lại với hai độ đo ``Normalized Discounted Cumulative Gain'' (NDCG) và ``Recall''.

Chúng tôi sử dụng một kiến trúc giống cho hai mô hình ``Auto-encoder'' và ``Variational Auto-encoder'' (VAEs). Với ``encoder'' và ``decoder'' là mạng nơ-ron nhiều lớp (``Multi-layer Perceptron'' hay MLP) có kiến trúc đối xứng nhau, kích thước véc-tơ biểu diễn ẩn của mô hình là 200. Kiến trúc của các mô hình trên với MLP có 1 tầng ẩn kích thước 600 có thể mô tả ngắn gọn là $[ I \to 600 \to 200 \to 600 \to I ]$, với I là số lượng sản phẩm. Áp dụng hàm kích hoạt phi tuyến là \textit{tanh} giữa các lớp, tuy nhiên, do đầu ra của ``encoder'' trong mô hình VAEs là một biến ngẫu nhiên từ phân phối xác suất, do đó chúng tôi không áp dụng hàm kích hoạt tầng đó.

Ngoài ra, như đã trình bày ở phần ..., chúng tôi áp dụng kỹ thuật ``drop-out'' cho véc-tơ đầu vào để mô hình sinh ra gợi ý cũng như tránh tình trạng ``over-fitting''.

Như đề xuất của tác giả Liang trong bài báo \cite{mvae}, chúng tôi sử dụng ``Multinomal log-likelihood'' làm hàm tính độ lỗi cho cả hai mô hình. Chúng tôi gọi mô hình là ``Variational Auto-encoder'' với hàm lỗi này là Mult-VAEs, mô hình ``Auto-encoder'' với hàm lỗi và phần ``drop-out'' là Mult-DAE.

Chúng tôi điều chỉnh siêu tham số $\beta$ của mô hình Mult-VAEs với 200,000 bước cập nhật theo phương pháp đã trình bày ở phần ... . Và áp dụng một lượng ``weight-decay'' 0.01 cho Mult-DAE. 

Chúng tôi lần lượt huấn luyện hai mô hình Mult-VAEs và Mult-DAE bằng thuật toán Adam <cite> trên các tập dữ liệu MovieLens \cite{Ml20M} với 200 ``epoch'' và Million Song Dataset \cite{MSD} với 100 ``epoch'' (mỗi ``epoch'' là một lần mô hình duyệt qua hết dữ liệu huấn luyện). Chúng tôi lưu lại mô hình cho kết quả tốt nhất với độ đo NDCG@100 trên tập đánh giá để đánh giá kết quả trên tập kiểm tra (testing).







\section{Các kết quả thí nghiệm}
    \subsection{Kết quả của mô hình cài đặt so với bài báo}
    Trong phần này, chúng tôi sẽ trình bày kết quả của mô hình mà chúng tôi cài đặt. 
    Cụ thể, chúng tôi so sánh kết quả mô hình Mult-VAEs và Mult-DAE chúng tôi cài đặt so với kết quả trong bài báo.
    Các mô hình được đánh giá trên tập kiểm tra gồm 10,000 người dùng trong tập dữ liệu MovieLens và 50,000 người dùng trong tập Million Song Dataset.
    Chúng tôi dùng các độ đo giống với mô tả trong bài báo là:
    \begin{itemize}
        \item NDCG@100: độ đo NDCG trên tối đa 100 sản phẩm được mô hình xếp hạng cao nhất.
        \item Recall@50: độ đo Recall trên tối đa 50 sản phẩm được mô hình xếp hạng cao nhất.
        \item Recall@20: độ đo Recall trên tối đa 20 sản phẩm được mô hình xếp hạng cao nhất.
    \end{itemize}

    Từ kết quả trên bảng~\ref{table_ML20MResult}, ở tập dữ liệu MovieLens, cả hai mô hình chúng tôi cài đặt đều đạt được kết quả tương đồng so với kết quả trong bài báo \cite{mvae}.
    \begin{table}[]
        \centering
        \begin{tabular}{|l|c|c|c|}
            \hline
                            & \textbf{Recall@20} & \textbf{Recall@50} & \textbf{NDCG@100} \\ \hline
            \textbf{Mult-VAEs} & 0.395              & 0.537              & 0.429             \\ \hline
            \textbf{\begin{tabular}[c]{@{}l@{}}Mult-VAEs\\ (cài đặt của tác giả)\end{tabular}} & 0.395 & 0.537 & 0.426 \\ \hline
            \textbf{Mult-DAE} & 0.398              & 0.535              & 0.423             \\ \hline
            \textbf{\begin{tabular}[c]{@{}l@{}}Mult-DAE\\ (cài đặt của tác giả)\end{tabular}}  & 0.387 & 0.524 & 0.419 \\ \hline
            \end{tabular}
        \label{table_ML20MResult}
        \caption[Kết quả cài đặt trên tập MovieLens]{Kết quả cài đặt trên tập MovieLens so với kết quả trong bài báo \cite{mvae}}
        \end{table}

        
    Với các kết quả tập dữ liệu MSD được thể hiện trong bảng~\ref{table_MSDResult}, cả hai mô hình chúng tôi cài đặt cho kết quả có sai lệch so với kết quả trong bài báo.
    Nhìn chung, kết quả của Mult-VAEs và Mult-DAE ở cả 3 độ đo đều tương quan so với kết quả của bài báo.
    \begin{table}[]
        \centering
        \begin{tabular}{|l|c|c|c|}
        \hline
                            & \textbf{Recall@20} & \textbf{Recall@50} & \textbf{NDCG@100} \\ \hline
        \textbf{Mult-VAEs} & 0.257              & 0.353              & 0.308             \\ \hline
        \textbf{\begin{tabular}[c]{@{}l@{}}Mult-VAEs\\ (cài đặt của tác giả)\end{tabular}} & 0.266 & 0.364 & 0.316 \\ \hline
        \textbf{Mult-DAE} & 0.256              & 0.351              & 0.306             \\ \hline
        \textbf{\begin{tabular}[c]{@{}l@{}}Mult-DAE\\ (cài đặt của tác giả)\end{tabular}}  & 0.266 & 0.363 & 0.313 \\ \hline
        \end{tabular}
        \label{table_MSDResult}
        \caption[Kết quả cài đặt trên tập MSD]{Kết quả cài đặt trên tập MSD so với kết quả trong bài báo \cite{mvae}}
    \end{table}

    Với mô hình Mult-VAEs, cài đặt của tác giả Lobel và các cộng sự trong bài báo ``RACT: TOWARDS AMORTIZED RANKING-CRITICAL
    TRAINING FOR COLLABORATIVE FILTERING'' \cite{ract}, mô hình của tác giả cài đặt cũng cho kết quả tương đồng với mô hình chúng tôi cài đặt, với sai số nhỏ.
    Theo đó, kết quả trên tập dữ liệu MovieLens tương đồng với bài báo gốc \cite{mvae}và kết quả trên tập dữ liệu MSD (được trình bày trong bảng~\ref{table_compareMSD}) thấp hơn bài báo gốc, tuy nhiên sai số không quá lớn. 

    
    Qua các kết quả trên, chúng tôi rút ra nhận xét như sau. Mult-VAEs cho kết quả tốt hơn Mult-DAE ở cả 3 độ đo trên tập dữ liệu MovieLens.
    Với tập dữ liệu có kích thước lớn hơn là MSD, cả Mult-VAEs và Mult-DAE đều cho kết quả khá gần nhau ở cả 3 độ đo, tương đồng với kết quả của hai mô hình này trong bài báo gốc \cite{mvae}.
    

    \begin{table}[]
        \centering
        \begin{tabular}{|l|c|c|c|}
        \hline
                                                                                                & \textbf{Recall@20} & \textbf{Recall@50} & \textbf{NDCG@100} \\ \hline
        \textbf{Mult-VAEs}                                                                       & 0.257              & 0.353              & 0.308             \\ \hline
        \textbf{\begin{tabular}[c]{@{}l@{}}Mult-VAEs\\ (cài đặt của tác giả Lobel)\end{tabular}} & 0.260              & 0.356              & 0.310             \\ \hline
        \textbf{\begin{tabular}[c]{@{}l@{}}Mult-VAEs\\ (cài đặt của tác giả Liang)\end{tabular}} & 0.266              & 0.364              & 0.316             \\ \hline
        \end{tabular}
        \label{table_compareMSD}
        \caption[]{Kết quả cài đặt của chúng tôi so với kết quả cài đặt trong bài báo của tác giả Lobel \cite{ract} và  bài báo của tác giả Liang \cite{mvae} trên tập dữ liệu MSD}
        \end{table}
    \subsection{Phân tích ``Multinomal Likelihood''}
        Như đã trình bày trong phần~\ref{Mult-likelighood}, với giả định véc-tơ tương tác của người dùng trên toàn bộ tập sản phẩm được phát sinh từ một phân phối đa thức (``Multinomial Distribution''), kết quả trả về của mô hình Mult-VAEs là một véc-tơ thể hiện xác suất được chọn của từng sản phẩm trong hệ thống (véc-tơ này có tổng bằng 1). Chúng tôi tiến hành thay đổi hàm lỗi ``Multinomial log-likelihood'' thành các hàm lỗi ``Gaussian likelihood'' và ``Logistic log-likelihood'' trên hai mô hình ``Variational Auto-encoder'' và ``Auto-encoder'' với các thiết lập giống phần~\ref{setup_experiment}. 

        Vì tính chất của ``Multinomial log-likelihood'' phụ vụ mục đích xếp hạng các sản phẩm ``phù hợp'' với người dùng, do đó chúng tôi dùng độ đo Normalized Discounted Cumulative Gain (NDCG) để đánh giá chất lượng xếp hạng của mô hình. Bảng~\ref{table_comparelikelihood} thể hiện độ đo NDCG@100 với các hàm lỗi và mô hình tương ứng. 
        
        Qua các kết quả trên, ta có thể thấy các mô hình với hàm lỗi ``Multinomial log-likelihood'' có chất lượng xếp hạng tốt hơn hai hàm lỗi còn lại.
        Từ đó cho thấy ``Multinomial log-likelihood'' là một hàm lỗi phù hợp với hệ thống gợi ý, khi chúng ta muốn ``xếp hạng'' các sản phẩm, từ đó đưa ra các gợi ý tốt nhất cho người dùng.

        \begin{table}[]
        \centering
            \begin{tabular}{|c|c|c|c|}
            \hline
                          & \textbf{Multinomial}                  & \textbf{Gaussian}            & \textbf{Logistics}           \\ \hline
            \textbf{VAEs} &  \textbf{0.429} & 0.422 &  0.419 \\ \hline
            \textbf{DAE}  & \textbf{0.423}                        & 0.409                        & 0.412                        \\ \hline
            \end{tabular}
        \label{table_comparelikelihood}
        \caption[]{Độ đo NDCG@100 trên các mô hình VAEs và DAE với các hàm lỗi khác nhau trên tập dữ liệu MovieLens}
        \end{table}



    \subsection{So sánh với Variational Auto-encoder và Auto-encoder}
